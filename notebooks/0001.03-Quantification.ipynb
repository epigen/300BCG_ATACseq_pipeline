{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pybedtools as bedtools \n",
    "import shutil\n",
    "from multiprocessing import Pool\n",
    "import traceback,sys\n",
    "import numpy as np \n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_root= os.path.join(\"/\",\"nobackup\",\"lab_bsf\",\"users\",\"dbarreca\")\n",
    "tmp_dir = os.path.join(tmp_root,\"tmp_quantify\")\n",
    "\n",
    "data_folder= os.path.join(\"..\",\"data\")\n",
    "analysis_folder= os.path.join(data_folder,\"quantification\")\n",
    "\n",
    "annotations_file= os.path.join(data_folder,\"complete_metadata.csv\")\n",
    "atac_folder = os.path.join(data_folder,\"pipeline_out\",\"results\")\n",
    "\n",
    "resources_folder=os.path.join(\"..\",\"references\")\n",
    "chrom_file = os.path.join(resources_folder, 'hg38.chrom.sizes')\n",
    "blacklist_file=os.path.join(resources_folder, 'hg38.blacklist.bed')\n",
    "\n",
    "suffix=\"ALL\"\n",
    "peaks_file = os.path.join(analysis_folder,\"consensus_set_{}.bed\".format(suffix))\n",
    "peaks_file_hg19 = os.path.join(analysis_folder,\"consensus_set_{}_hg19.bed\".format(suffix))\n",
    "peaks_file_unmapped = os.path.join(analysis_folder,\"consensus_set_{}_unmapped.bed\".format(suffix))\n",
    "\n",
    "binary_file = os.path.join(analysis_folder,\"quantification_binary_{}-set.csv\".format(suffix))\n",
    "count_file = os.path.join(analysis_folder,\"quantification_{}-set.csv\".format(suffix))\n",
    "\n",
    "sloop_extension=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(annotations_file,index_col=0)\n",
    "\n",
    "annotations=annotations[(annotations['QC:PASS']==True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define consensus peak set\n",
    "\n",
    "Peak set is defined only on the \"PASS FILTER\" samples to avoid spourious region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir)\n",
    "    \n",
    "bedtools.helpers.set_tempdir(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_peaks(peakfiles, output, isPeak = True, size=sloop_extension,blacklist_file=blacklist_file):\n",
    "    output_bed= None\n",
    "  \n",
    "    for peakfile in peakfiles:\n",
    "        peak_bed = bedtools.BedTool(peakfile)\n",
    "        if (isPeak and blacklist_file is not None):\n",
    "            peak_bed=peak_bed.intersect(blacklist_file,v=True, wa=True)\n",
    "        if (isPeak):\n",
    "            peak_bed = peak_bed.slop(g=chrom_file, b=size)\n",
    "            \n",
    "        if (output_bed is None):\n",
    "            output_bed = peak_bed\n",
    "        else:\n",
    "            output_bed = output_bed.cat(peak_bed,force_truncate=True)\n",
    "            \n",
    "    output_bed.saveas(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (suffix in ['PBMC','ALL']):\n",
    "    selected_samples = list(annotations[annotations['SAMPLE:TISSUE']=='PBMC'].index)\n",
    "\n",
    "if (suffix=='ALL'):\n",
    "     selected_samples += list(\n",
    "         annotations[\n",
    "             (annotations['SAMPLE:TISSUE'].isin(['nkcell','monocyte','cd8t'])) & \n",
    "            (annotations['SAMPLE:VISIT'] == 'V1')\n",
    "         ].index\n",
    "     )\n",
    "                  \n",
    "                  \n",
    "peakfiles = [os.path.join(atac_folder,sample,'peaks','{}_summits.bed'.format(sample)) for sample in selected_samples]          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = list()\n",
    "\n",
    "cpus = 16\n",
    "pool = Pool(cpus)\n",
    "\n",
    "for i,peakfiles_subset in enumerate(np.array_split(peakfiles, cpus)):\n",
    "    output = os.path.join(tmp_dir,'tmp_{}.bed'.format(i))\n",
    "    futures.append(pool.apply_async(merge_peaks,args=(peakfiles_subset, output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [result.get() for result in futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = os.path.join(tmp_dir,'final.bed'.format(i))\n",
    "merge_peaks(outputs,output, isPeak=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = bedtools.BedTool(output).sort(faidx=chrom_file).to_dataframe(names=['CHR','START','END'],dtype={'START':int,'END':int})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks['ID'] = peaks.index.format(formatter=(lambda x: \"CONS{:011d}\".format(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedtools.BedTool().from_dataframe(peaks).saveas(peaks_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(peaks)\n",
    "del(futures)\n",
    "del(outputs)\n",
    "del(peakfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash -s $peaks_file $peaks_file_hg19 $peaks_file_unmapped\n",
    "echo \"Performing liftOver ${1} ~/resources/hg38ToHg19.over.chain.gz ${2} ${3}\"\n",
    "liftOver ${1} ~/resources/hg38ToHg19.over.chain.gz ${2} ${3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quantify\n",
    "\n",
    "Quantification is run on all the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir)\n",
    "    \n",
    "bedtools.helpers.set_tempdir(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_peaks = bedtools.BedTool(peaks_file)\n",
    "consensus_peaks_df = bedtools.BedTool(peaks_file).to_dataframe().set_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_subdir = 'peaks'\n",
    "peaks_format = '{}_summits.bed'\n",
    "\n",
    "def get_peaks(sample):\n",
    "    return os.path.join(atac_folder,sample,peaks_subdir,peaks_format.format(sample))\n",
    "\n",
    "\n",
    "def get_coverage_bin(sample):\n",
    "    peakfile=get_peaks(sample)\n",
    "    result = pd.DataFrame(0,index=consensus_peaks_df.index,columns=[sample])\n",
    "    try:\n",
    "        if (peakfile is not None):\n",
    "            sample_peaks = bedtools.BedTool(peakfile)\n",
    "            result = consensus_peaks.intersect(\n",
    "                sample_peaks,\n",
    "                g=chrom_file, \n",
    "                wa=True,\n",
    "                c=True\n",
    "            ).to_dataframe(index_col='name',\n",
    "                usecols=[3,4],\n",
    "                names=['name',sample]\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(\"Error occured while processing sample \"+sample)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "    finally:\n",
    "        return result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=Pool(16).map(get_coverage_bin,[sample for sample in annotations.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [item for item in results if item is not None]\n",
    "results = pd.concat(results).T\n",
    "results.to_csv(binary_file,index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(consensus_peaks_df)\n",
    "del(consensus_peaks)\n",
    "del(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bam(sample):\n",
    "    return os.path.join(atac_folder,sample,bam_subdir,bam_format.format(sample))\n",
    "\n",
    "def get_coverage(sample):\n",
    "    print(\"Processing \"+sample)\n",
    "    try:\n",
    "        result= elements_to_quantify.coverage(b=get_bam(sample),sorted=True,g=chrom_file).to_dataframe(\n",
    "                    names=[\"CHR\", \"START\", \"END\", \"ID\", sample, \"NA1\", \"NA2\", \"NA3\"],\n",
    "                    dtype={sample: int},\n",
    "                    usecols=['ID', sample],\n",
    "                    index_col='ID').T\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(\"Error occured while processing sample \"+sample)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        return pd.DataFrame(0,index=elements_to_quantify.index,columns=[sample]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_subdir = 'mapped'\n",
    "bam_format = '{}.trimmed.bowtie2.filtered.shifted.events.bed'\n",
    "elements_to_quantify = bedtools.BedTool(peaks_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir)\n",
    "    \n",
    "bedtools.helpers.set_tempdir(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=Pool(16).map(get_coverage, [sample for sample in annotations.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [item for item in result if item is not None]\n",
    "result = pd.concat(result)\n",
    "result.T.to_csv(count_file,index_label='ID')\n",
    "shutil.rmtree(tmp_dir)\n",
    "del(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculate average tracks (wiggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_dir=os.path.join(analysis_folder,\"summary_tracks\")\n",
    "if not os.path.exists(tracks_dir):\n",
    "    os.makedirs(tracks_dir)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_annotations=annotations[(annotations['SAMPLE:TISSUE']=='PBMC') | (annotations['SAMPLE:VISIT']=='V1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_samples(data,atac_dir=atac_folder,out_dir=tracks_dir, chrom_file=chrom_file):\n",
    "    job_name=data[0]\n",
    "    samples=data[1]\n",
    "    \n",
    "    out_file=os.path.realpath(os.path.abspath(\n",
    "        os.path.join(out_dir,\"{}.wiggle\".format(job_name))\n",
    "    ))\n",
    "    cmd=\"wiggletools median \"\n",
    "    cmd+=\" \".join(samples.map(lambda sample: os.path.realpath(os.path.abspath(\n",
    "        os.path.join(atac_dir,sample,\"coverage\",\"{}.bigWig\".format(sample))\n",
    "        ))))\n",
    "    cmd+=\" > {}\".format(out_file)\n",
    "    print(\"RUNNING {}\".format(job_name))\n",
    "    returnvalue=os.system(cmd)\n",
    "    print(\"{}-wiggletools RETURNED {}\".format(job_name,returnvalue))\n",
    "    if (returnvalue==\"0\"):\n",
    "        final_file=os.path.realpath(os.path.abspath(\n",
    "            os.path.join(out_dir,\"{}.bigWig\".format(job_name))\n",
    "        ))\n",
    "        cmd=\"wigToBigWig {} {} {}\".format(out_file,chrom_file,final_file)        \n",
    "        returnvalue=os.system(cmd)\n",
    "        print(\"{}-wigToBigWig RETURNED {}\".format(job_name,returnvalue))\n",
    "        return int(returnvalue)\n",
    "    else:\n",
    "        return int(returnvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pool(16).map(run_samples,\n",
    "             [(\"{}_{}\".format(index[0],index[1]), df.index) for index, df in tracks_annotations.groupby(['SAMPLE:TISSUE','SAMPLE:VISIT'])]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BCG (postprocessing)",
   "language": "python",
   "name": "bcg_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
